{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N1c-C/Group-13-Sprint/blob/Main_Nic/colab_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51bQlVgjmnWf"
      },
      "source": [
        "# YoloV3 TF2 GPU Colab Notebook\n",
        "\n",
        "##### 1.  Clone and install dependencies \n",
        "\n",
        "**IMPORTANT**: Restart following the instruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpn-5i4VHbht",
        "outputId": "be89f01b-15bc-4c97-a08f-717bea870a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/zzh8829/yolov3-tf2\n",
        "%cd yolov3-tf2/\n",
        "!pip install -r requirements-gpu.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3-tf2'...\n",
            "remote: Enumerating objects: 439, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 439 (delta 2), reused 0 (delta 0), pack-reused 433\u001b[K\n",
            "Receiving objects: 100% (439/439), 4.24 MiB | 4.40 MiB/s, done.\n",
            "Resolving deltas: 100% (250/250), done.\n",
            "/content/yolov3-tf2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/yolov3-tf2 (from -r requirements-gpu.txt (line 6))\n",
            "Collecting tensorflow-gpu==2.5.1\n",
            "  Downloading tensorflow_gpu-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 9.9 kB/s \n",
            "\u001b[?25hCollecting opencv-python==4.2.0.32\n",
            "  Downloading opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (28.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2 MB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from -r requirements-gpu.txt (line 3)) (4.2.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements-gpu.txt (line 4)) (4.64.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.37.1)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.6.3)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.17.3)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (2.8.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu==2.5.1->-r requirements-gpu.txt (line 1)) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68714 sha256=bb2dcd99b2d5d24387a1c0608d8bd38fb75afda772c0a26cc70452eea6c01109\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, yolov3-tf2, tensorflow-gpu, opencv-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.1.0\n",
            "    Uninstalling absl-py-1.1.0:\n",
            "      Successfully uninstalled absl-py-1.1.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Running setup.py develop for yolov3-tf2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 opencv-python-4.2.0.32 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.1 typing-extensions-3.7.4.3 wrapt-1.12.1 yolov3-tf2-0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIUMAdGXm46J"
      },
      "source": [
        "##### 2.  Check Tensorflow2 version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyrsdB9THu-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "89f319a3-216e-4890-c284-23638ec5ab3c"
      },
      "source": [
        "%cd yolov3-tf2/\n",
        "!ls\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3-tf2\n",
            "checkpoints\t data\t\t  README.md\t\ttrain.py\n",
            "colab_gpu.ipynb  detect.py\t  requirements-gpu.txt\tyolov3_tf2\n",
            "conda-cpu.yml\t detect_video.py  requirements.txt\tyolov3_tf2.egg-info\n",
            "conda-gpu.yml\t docs\t\t  setup.py\n",
            "convert.py\t LICENSE\t  tools\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxD-M-g4nZf_"
      },
      "source": [
        "##### 3.  Convert Pretrained Darknet Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xymK200gmV25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a89e2c-6f18-4eac-8efc-d359870fb02d"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\n",
        "!python convert.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-06 13:20:08--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘data/yolov3.weights’\n",
            "\n",
            "data/yolov3.weights 100%[===================>] 236.52M  17.9MB/s    in 14s     \n",
            "\n",
            "2022-07-06 13:20:23 (16.7 MB/s) - ‘data/yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "2022-07-06 13:20:24.065123: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-07-06 13:20:26.476405: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2022-07-06 13:20:26.561005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.561903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-07-06 13:20:26.561974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-07-06 13:20:26.644911: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2022-07-06 13:20:26.645050: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-07-06 13:20:26.682706: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2022-07-06 13:20:26.704617: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2022-07-06 13:20:26.783149: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
            "2022-07-06 13:20:26.818973: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-07-06 13:20:26.824328: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-07-06 13:20:26.824497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.825205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.825933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2022-07-06 13:20:26.923957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-06 13:20:26.924336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.925379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-07-06 13:20:26.925542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.926448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:26.927349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2022-07-06 13:20:26.927443: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-07-06 13:20:28.001007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-07-06 13:20:28.001074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2022-07-06 13:20:28.001212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2022-07-06 13:20:28.001496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:28.002440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:28.003277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-06 13:20:28.004157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13803 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "W0706 13:20:30.854893 139623373846400 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Functional)       ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Functional)        (None, None, None, 5 11024384    yolo_darknet[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Functional)        (None, None, None, 2 2957312     yolo_conv_0[0][0]                \n",
            "                                                                 yolo_darknet[0][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Functional)        (None, None, None, 1 741376      yolo_conv_1[0][0]                \n",
            "                                                                 yolo_darknet[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Functional)      (None, None, None, 3 4984063     yolo_conv_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Functional)      (None, None, None, 3 1312511     yolo_conv_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Functional)      (None, None, None, 3 361471      yolo_conv_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((1, None, 4), (1, N 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I0706 13:20:30.899868 139623373846400 convert.py:24] model created\n",
            "I0706 13:20:30.901456 139623373846400 utils.py:45] yolo_darknet/conv2d bn\n",
            "I0706 13:20:30.904777 139623373846400 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I0706 13:20:30.908165 139623373846400 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I0706 13:20:30.911180 139623373846400 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I0706 13:20:30.914120 139623373846400 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I0706 13:20:30.917854 139623373846400 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I0706 13:20:30.920822 139623373846400 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I0706 13:20:30.930290 139623373846400 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I0706 13:20:30.933267 139623373846400 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I0706 13:20:30.936858 139623373846400 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I0706 13:20:30.942571 139623373846400 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I0706 13:20:30.945764 139623373846400 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I0706 13:20:30.950146 139623373846400 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I0706 13:20:30.953198 139623373846400 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I0706 13:20:30.957469 139623373846400 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I0706 13:20:30.960365 139623373846400 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I0706 13:20:30.964996 139623373846400 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I0706 13:20:30.967983 139623373846400 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I0706 13:20:30.972349 139623373846400 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I0706 13:20:30.975133 139623373846400 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I0706 13:20:30.979999 139623373846400 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I0706 13:20:30.983039 139623373846400 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I0706 13:20:30.987661 139623373846400 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I0706 13:20:30.990577 139623373846400 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I0706 13:20:30.994841 139623373846400 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I0706 13:20:30.997828 139623373846400 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I0706 13:20:31.003980 139623373846400 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I0706 13:20:31.015791 139623373846400 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I0706 13:20:31.019526 139623373846400 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I0706 13:20:31.028309 139623373846400 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I0706 13:20:31.038778 139623373846400 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I0706 13:20:31.050015 139623373846400 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I0706 13:20:31.052793 139623373846400 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I0706 13:20:31.061551 139623373846400 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I0706 13:20:31.065433 139623373846400 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I0706 13:20:31.074144 139623373846400 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I0706 13:20:31.077626 139623373846400 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I0706 13:20:31.089648 139623373846400 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I0706 13:20:31.092420 139623373846400 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I0706 13:20:31.100543 139623373846400 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I0706 13:20:31.103316 139623373846400 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I0706 13:20:31.111833 139623373846400 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I0706 13:20:31.115371 139623373846400 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I0706 13:20:31.123969 139623373846400 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I0706 13:20:31.165374 139623373846400 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I0706 13:20:31.172752 139623373846400 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I0706 13:20:31.223006 139623373846400 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I0706 13:20:31.230301 139623373846400 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I0706 13:20:31.271086 139623373846400 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I0706 13:20:31.284077 139623373846400 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I0706 13:20:31.386543 139623373846400 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I0706 13:20:31.393737 139623373846400 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I0706 13:20:31.428176 139623373846400 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I0706 13:20:31.434519 139623373846400 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I0706 13:20:31.471189 139623373846400 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I0706 13:20:31.477273 139623373846400 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I0706 13:20:31.512389 139623373846400 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I0706 13:20:31.519266 139623373846400 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I0706 13:20:31.592288 139623373846400 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I0706 13:20:31.595451 139623373846400 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I0706 13:20:31.598450 139623373846400 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I0706 13:20:31.601805 139623373846400 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I0706 13:20:31.610774 139623373846400 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I0706 13:20:31.614035 139623373846400 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I0706 13:20:31.622569 139623373846400 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I0706 13:20:31.625756 139623373846400 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I0706 13:20:31.634100 139623373846400 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I0706 13:20:31.636125 139623373846400 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I0706 13:20:31.638545 139623373846400 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I0706 13:20:31.640985 139623373846400 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I0706 13:20:31.645059 139623373846400 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I0706 13:20:31.647489 139623373846400 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I0706 13:20:31.651268 139623373846400 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I0706 13:20:31.653640 139623373846400 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I0706 13:20:31.657512 139623373846400 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I0706 13:20:31.658931 139623373846400 convert.py:27] weights loaded\n",
            "2022-07-06 13:20:31.667181: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-07-06 13:20:33.963771: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
            "2022-07-06 13:20:33.966816: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
            "Traceback (most recent call last):\n",
            "  File \"convert.py\", line 39, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"convert.py\", line 30, in main\n",
            "    output = yolo(img)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1030, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 421, in call\n",
            "    inputs, training=training, mask=mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 556, in _run_internal_graph\n",
            "    outputs = node.layer(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1030, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 421, in call\n",
            "    inputs, training=training, mask=mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 556, in _run_internal_graph\n",
            "    outputs = node.layer(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1030, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 249, in call\n",
            "    outputs = self._convolution_op(inputs, self.kernel)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
            "    return target(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1019, in convolution_v2\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1149, in convolution_internal\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 2603, in _conv2d_expanded_batch\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 932, in conv2d\n",
            "    _ops.raise_from_not_ok_status(e, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 6897, in raise_from_not_ok_status\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySGg4Ols02rX"
      },
      "source": [
        "##### 4. Initialize Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlgBiU4ZsZY5"
      },
      "source": [
        "import sys\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "\n",
        "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "\n",
        "app._run_init(['yolov3'], app.parse_flags_with_usage)\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laxApAGV07kw"
      },
      "source": [
        "##### 4. Detect Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iKC1pvBnkDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "18809bb8-734f-40fb-e965-412fe6bbacd7"
      },
      "source": [
        "FLAGS.image = 'data/meme.jpg'\n",
        "\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "      \n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "img_raw = tf.image.decode_image(\n",
        "    open(FLAGS.image, 'rb').read(), channels=3)\n",
        "\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "t1 = time.time()\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "t2 = time.time()\n",
        "logging.info('time: {}'.format(t2 - t1))\n",
        "\n",
        "logging.info('detections:')\n",
        "for i in range(nums[0]):\n",
        "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
        "                                        np.array(scores[0][i]),\n",
        "                                        np.array(boxes[0][i])))\n",
        "\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0706 13:20:37.949321 139897966598016 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints/yolov3.tf",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b1b93607b63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYoloV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2288\u001b[0m           'True when by_name is True.')\n\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m     \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_detect_save_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_detect_save_format\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m   2914\u001b[0m   \u001b[0;31m# directory. It's possible for filepath to be both a prefix and directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m   \u001b[0;31m# Prioritize checkpoint over SavedModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2916\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0m_is_readable_tf_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2917\u001b[0m     \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0msm_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_is_readable_tf_checkpoint\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m   2935\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_readable_tf_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     37\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints/yolov3.tf"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up4Xcad81FSa"
      },
      "source": [
        "##### 5. Training New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I8Ml-j4Iyuv"
      },
      "source": [
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar -O ./data/voc2009_raw.tar\n",
        "!mkdir -p ./data/voc2009_raw\n",
        "!tar -xf ./data/voc2009_raw.tar -C ./data/voc2009_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lvttM39I5Na"
      },
      "source": [
        "!python tools/voc2012.py \\\n",
        "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
        "  --split train \\\n",
        "  --output_file ./data/voc_train.tfrecord\n",
        "\n",
        "!python tools/voc2012.py \\\n",
        "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\n",
        "  --split val \\\n",
        "  --output_file ./data/voc_val.tfrecord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjLHBgPKblm"
      },
      "source": [
        "!python tools/visualize_dataset.py --dataset ./data/voc_train.tfrecord --classes=./data/voc2012.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OVCJuxQKuMM"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='./output.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBhryo1I2dwG"
      },
      "source": [
        "!python train.py \\\n",
        "\t--dataset ./data/voc_train.tfrecord \\\n",
        "\t--val_dataset ./data/voc_val.tfrecord \\\n",
        "\t--classes ./data/voc2012.names \\\n",
        "\t--num_classes 20 \\\n",
        "\t--mode fit --transfer darknet \\\n",
        "\t--batch_size 16 \\\n",
        "\t--epochs 3 \\\n",
        "\t--weights ./checkpoints/yolov3.tf \\\n",
        "\t--weights_num_classes 80 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgtlCN1m1TKG"
      },
      "source": [
        "##### 6. Detect using new weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wok7x44vNYuP"
      },
      "source": [
        "FLAGS.num_classes = 20\n",
        "FLAGS.classes = 'data/voc2012.names'\n",
        "FLAGS.weights = 'checkpoints/yolov3_train_3.tf'\n",
        "FLAGS.image = 'data/meme.jpg'\n",
        "\n",
        "# Lower threshold due to insufficient training\n",
        "FLAGS.yolo_iou_threshold = 0.2\n",
        "FLAGS.yolo_score_threshold = 0.2\n",
        "\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "img_raw = tf.image.decode_image(\n",
        "    open(FLAGS.image, 'rb').read(), channels=3)\n",
        "\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "t1 = time.time()\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "t2 = time.time()\n",
        "logging.info('time: {}'.format(t2 - t1))\n",
        "\n",
        "logging.info('detections:')\n",
        "for i in range(nums[0]):\n",
        "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
        "                                        np.array(scores[0][i]),\n",
        "                                        np.array(boxes[0][i])))\n",
        "\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esTFKZzX7jYj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}